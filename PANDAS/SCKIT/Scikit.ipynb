{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos Numpy y la biblioteca de algebra lineal (linalg)\n",
    "import numpy as np\n",
    "from numpy import linalg\n",
    "\n",
    "np.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Ejemplo mínimo de NumPy\n",
    "\n",
    "v = np.array([1,2,3])\n",
    "print(v)\n",
    "print(v[1])\n",
    "\n",
    "m = np.array([[1,2,3],[0,1,4],[5,6,0]])\n",
    "print(m)\n",
    "print(m[2,1])\n",
    "\n",
    "# Multiplicación vector-matriz\n",
    "print(m @ v)\n",
    "\n",
    "# Inversa de una matriz\n",
    "m_inv = linalg.inv(m)\n",
    "print(m_inv)\n",
    "\n",
    "# Multiplicación matriz-matriz\n",
    "print(m @ m_inv)\n",
    "\n",
    "# Debería dar como valor la matriz identidad, alguno de los elementos son muy cercanos a 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Carga desde fichero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.4'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pandas como hemos visto es una biblioteca utilizada para el análisis de datos, basada en Numpy.\n",
    "import pandas as pd\n",
    "pd.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga el fichero de datos de pasajeros del Titanic.\n",
    "df = pd.read_csv(\"titanic.csv\")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "PassengerId: identificador único del pasajero.\n",
    "\n",
    "Survived: si el pasajero sobrevivió al naufragio, codificada como 0 (no) y 1 (si). Esta es la variable respuesta que interesa predecir.\n",
    "\n",
    "Pclass: clase a la que pertenecía el pasajero: 1, 2 o 3.\n",
    "\n",
    "Name: nombre del pasajero.\n",
    "\n",
    "Sex: sexo del pasajero.\n",
    "\n",
    "Age: edad del pasajero.\n",
    "\n",
    "SibSp: número de hermanos, hermanas, hermanastros o hermanastras en el barco.\n",
    "\n",
    "Parch: número de padres e hijos en el barco.\n",
    "\n",
    "Ticket: identificador del billete.\n",
    "\n",
    "Fare: precio pagado por el billete.\n",
    "\n",
    "Cabin: identificador del camarote asignado al pasajero.\n",
    "\n",
    "Embarked: puerto en el que embarcó el pasajero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lectura de todas las hojas de 'data/Cap5/subvenciones_totales.xls', devuelve un diccionario ordenado (str, DataFrame)\n",
    "# Con sheet_name = None cargamos todas las hojas del fichero. Y seleccionamos luego la hoja Totales.\n",
    "subvenciones = pd.read_excel('../../data/Cap 5/subvenciones_totales.xls', sheet_name=None)\n",
    "print(subvenciones['Totales'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizar y extraer información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "..           ...       ...     ...   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket     Fare Cabin Embarked  \n",
       "0        0         A/5 21171   7.2500   NaN        S  \n",
       "1        0          PC 17599  71.2833   C85        C  \n",
       "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3        0            113803  53.1000  C123        S  \n",
       "4        0            373450   8.0500   NaN        S  \n",
       "..     ...               ...      ...   ...      ...  \n",
       "886      0            211536  13.0000   NaN        S  \n",
       "887      0            112053  30.0000   B42        S  \n",
       "888      2        W./C. 6607  23.4500   NaN        S  \n",
       "889      0            111369  30.0000  C148        C  \n",
       "890      0            370376   7.7500   NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizar el principio y final de un DataFrame\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     PassengerId  Survived  Pclass  \\\n",
      "0              1         0       3   \n",
      "1              2         1       1   \n",
      "2              3         1       3   \n",
      "3              4         1       1   \n",
      "4              5         0       3   \n",
      "..           ...       ...     ...   \n",
      "886          887         0       2   \n",
      "887          888         1       1   \n",
      "888          889         0       3   \n",
      "889          890         1       1   \n",
      "890          891         0       3   \n",
      "\n",
      "                                                  Name     Sex   Age  SibSp  \\\n",
      "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
      "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
      "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
      "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
      "4                             Allen, Mr. William Henry    male  35.0      0   \n",
      "..                                                 ...     ...   ...    ...   \n",
      "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
      "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
      "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
      "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
      "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
      "\n",
      "     Parch            Ticket     Fare Cabin Embarked  \n",
      "0        0         A/5 21171   7.2500   NaN        S  \n",
      "1        0          PC 17599  71.2833   C85        C  \n",
      "2        0  STON/O2. 3101282   7.9250   NaN        S  \n",
      "3        0            113803  53.1000  C123        S  \n",
      "4        0            373450   8.0500   NaN        S  \n",
      "..     ...               ...      ...   ...      ...  \n",
      "886      0            211536  13.0000   NaN        S  \n",
      "887      0            112053  30.0000   B42        S  \n",
      "888      2        W./C. 6607  23.4500   NaN        S  \n",
      "889      0            111369  30.0000  C148        C  \n",
      "890      0            370376   7.7500   NaN        Q  \n",
      "\n",
      "[891 rows x 12 columns]\n"
     ]
    }
   ],
   "source": [
    "# Mostrar el principio y final de un DataFrame, en modo texto\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Índice pandas con las columnas de un DataFrame\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 12)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tamaño de un DataFrame\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.indexing._iLocIndexer'>\n"
     ]
    }
   ],
   "source": [
    "# .iloc para seleccionar por posición\n",
    "# con estos atributos se puede acceder a una porción de la tabla.\n",
    "\n",
    "print(type(df.iloc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId                           5\n",
       "Survived                              0\n",
       "Pclass                                3\n",
       "Name           Allen, Mr. William Henry\n",
       "Sex                                male\n",
       "Age                                35.0\n",
       "SibSp                                 0\n",
       "Parch                                 0\n",
       "Ticket                           373450\n",
       "Fare                               8.05\n",
       "Cabin                               NaN\n",
       "Embarked                              S\n",
       "Name: 4, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.iloc[4])   # Fila en la posición 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "\n",
       "   Parch     Ticket     Fare Cabin Embarked  \n",
       "0      0  A/5 21171   7.2500   NaN        S  \n",
       "1      0   PC 17599  71.2833   C85        C  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.iloc[:2])  # Filas en el rango [0,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.iloc[0,0]) # Celda (0,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Saundercock, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Name     Sex\n",
       "0           Braund, Mr. Owen Harris    male\n",
       "10  Sandstrom, Miss. Marguerite Rut  female\n",
       "12   Saundercock, Mr. William Henry    male"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.iloc[[0,10,12],3:5]) # Filas 0, 10 y 12, columnas 3:5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.indexing._LocIndexer'>\n"
     ]
    }
   ],
   "source": [
    "# .loc para seleccionar fragmentos de la tabla usando los índices, en el índice horizontal tenemos los nombres de las columnas,\n",
    "# en el vertical, usualmente tendremos posiciones, empezando por 0. Es más cómodo, usamos nombres y no posiciones.\n",
    "\n",
    "print(type(df.loc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId                          1\n",
       "Survived                             0\n",
       "Pclass                               3\n",
       "Name           Braund, Mr. Owen Harris\n",
       "Sex                               male\n",
       "Age                               22.0\n",
       "SibSp                                1\n",
       "Parch                                0\n",
       "Ticket                       A/5 21171\n",
       "Fare                              7.25\n",
       "Cabin                              NaN\n",
       "Embarked                             S\n",
       "Name: 0, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.loc[0])                # Fila con índice 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.25"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.loc[0,'Fare'])         # celda de la fila 0 y columna 'Fare'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex   Age  SibSp  Parch            Ticket     Fare\n",
       "0    male  22.0      1      0         A/5 21171   7.2500\n",
       "1  female  38.0      1      0          PC 17599  71.2833\n",
       "2  female  26.0      0      0  STON/O2. 3101282   7.9250\n",
       "3  female  35.0      1      0            113803  53.1000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.loc[:3, 'Sex':'Fare']) # Filas 0:3 (incluidas) en las columnas entre 'Sex':'Fare' (incluidas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>female</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>female</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>female</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Sex     Fare Embarked\n",
       "0    male   7.2500        S\n",
       "1  female  71.2833        C\n",
       "2  female   7.9250        S\n",
       "3  female  53.1000        S"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.loc[:3, ['Sex','Fare','Embarked']]) # Filas 0:3 (incluidas), y las columnas 'Sex','Fare' y 'Embarked'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>97</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Goldschmidt, Mr. George B</td>\n",
       "      <td>male</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17754</td>\n",
       "      <td>34.6542</td>\n",
       "      <td>A5</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>117</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Connors, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>70.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370369</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>494</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Artagaveytia, Mr. Ramon</td>\n",
       "      <td>male</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17609</td>\n",
       "      <td>49.5042</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>631</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Barkworth, Mr. Algernon Henry Wilson</td>\n",
       "      <td>male</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>27042</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>A23</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>852</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Svensson, Mr. Johan</td>\n",
       "      <td>male</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>347060</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass                                  Name  \\\n",
       "96            97         0       1             Goldschmidt, Mr. George B   \n",
       "116          117         0       3                  Connors, Mr. Patrick   \n",
       "493          494         0       1               Artagaveytia, Mr. Ramon   \n",
       "630          631         1       1  Barkworth, Mr. Algernon Henry Wilson   \n",
       "851          852         0       3                   Svensson, Mr. Johan   \n",
       "\n",
       "      Sex   Age  SibSp  Parch    Ticket     Fare Cabin Embarked  \n",
       "96   male  71.0      0      0  PC 17754  34.6542    A5        C  \n",
       "116  male  70.5      0      0    370369   7.7500   NaN        Q  \n",
       "493  male  71.0      0      0  PC 17609  49.5042   NaN        C  \n",
       "630  male  80.0      0      0     27042  30.0000   A23        S  \n",
       "851  male  74.0      0      0    347060   7.7750   NaN        S  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.loc[df['Age']> 70])    # Filas con 'Age' > 70"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>71.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>70.5</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>71.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>74.0</td>\n",
       "      <td>male</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Age   Sex  Survived\n",
       "96   71.0  male         0\n",
       "116  70.5  male         0\n",
       "493  71.0  male         0\n",
       "630  80.0  male         1\n",
       "851  74.0  male         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.loc[df['Age']> 70, ['Age','Sex', 'Survived']])    # Filas con 'Age' > 70, mostrar la columna 'Age', Sex' y Survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId      int64\n",
       "Survived         int64\n",
       "Pclass           int64\n",
       "Name            object\n",
       "Sex             object\n",
       "Age            float64\n",
       "SibSp            int64\n",
       "Parch            int64\n",
       "Ticket          object\n",
       "Fare           float64\n",
       "Cabin           object\n",
       "Embarked        object\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tipos almacenados en cada columna\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200  \n"
     ]
    }
   ],
   "source": [
    "# Descripción de los valores de un DataFrame, podemos ver algunas medidas estadísticas como la media, la desviación típica,\n",
    "# valores mínimos y máximos e incluso cuartiles. Para cadenas de texto no tiene sentido hablar de medias artiméticas...\n",
    "# Unique nos indica el número de valores diferentes para una columna (Sex tiene dos valores p.e.), otro dato curioso\n",
    "# es que no hay nombres repetidos 891. También se incluyen las filas Top para el elemento más repetido, y freq que indica\n",
    "# el número de repeticiones.\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://upload.wikimedia.org/wikipedia/commons/thumb/8/8c/Standard_deviation_diagram.svg/450px-Standard_deviation_diagram.svg.png "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Algunos datos de interés para la edad:\n",
    "   - La columna Age tiene 714 valores no vacíos, siendo 0.42 el valor mínimo y 80 el valor máximo.\n",
    "   - La edad media de los pasajeros es de 29.7 años, con una desviación típica de 14.52 (nos da idea de la dispersión).\n",
    "   - La mediana es de 28 años y el rango intercuartílico está entre 20.125 y 38 años."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        PassengerId    Survived      Pclass                           Name  \\\n",
      "count    891.000000  891.000000  891.000000                            891   \n",
      "unique          NaN         NaN         NaN                            891   \n",
      "top             NaN         NaN         NaN  Ilmakangas, Miss. Pieta Sofia   \n",
      "freq            NaN         NaN         NaN                              1   \n",
      "mean     446.000000    0.383838    2.308642                            NaN   \n",
      "std      257.353842    0.486592    0.836071                            NaN   \n",
      "min        1.000000    0.000000    1.000000                            NaN   \n",
      "25%      223.500000    0.000000    2.000000                            NaN   \n",
      "50%      446.000000    0.000000    3.000000                            NaN   \n",
      "75%      668.500000    1.000000    3.000000                            NaN   \n",
      "max      891.000000    1.000000    3.000000                            NaN   \n",
      "\n",
      "         Sex         Age       SibSp       Parch    Ticket        Fare  \\\n",
      "count    891  714.000000  891.000000  891.000000       891  891.000000   \n",
      "unique     2         NaN         NaN         NaN       681         NaN   \n",
      "top     male         NaN         NaN         NaN  CA. 2343         NaN   \n",
      "freq     577         NaN         NaN         NaN         7         NaN   \n",
      "mean     NaN   29.699118    0.523008    0.381594       NaN   32.204208   \n",
      "std      NaN   14.526497    1.102743    0.806057       NaN   49.693429   \n",
      "min      NaN    0.420000    0.000000    0.000000       NaN    0.000000   \n",
      "25%      NaN   20.125000    0.000000    0.000000       NaN    7.910400   \n",
      "50%      NaN   28.000000    0.000000    0.000000       NaN   14.454200   \n",
      "75%      NaN   38.000000    1.000000    0.000000       NaN   31.000000   \n",
      "max      NaN   80.000000    8.000000    6.000000       NaN  512.329200   \n",
      "\n",
      "              Cabin Embarked  \n",
      "count           204      889  \n",
      "unique          147        3  \n",
      "top     C23 C25 C27        S  \n",
      "freq              4      644  \n",
      "mean            NaN      NaN  \n",
      "std             NaN      NaN  \n",
      "min             NaN      NaN  \n",
      "25%             NaN      NaN  \n",
      "50%             NaN      NaN  \n",
      "75%             NaN      NaN  \n",
      "max             NaN      NaN  \n"
     ]
    }
   ],
   "source": [
    "# Si queremos que describe incluya todas las columnas, incluidas las no numéricas, le pasamos el parámetro include = 'all'\n",
    "# Es interesante observar en este caso que aparece la variable unique, nos indica el número de pasajeros, sexo = 2, Embarked = 3; \n",
    "# top elemento más repetido y freq las repeticiones de este elemento.\n",
    "print(df.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values [PassengerId]: 0\n",
      "Missing values [Survived]: 0\n",
      "Missing values [Pclass]: 0\n",
      "Missing values [Name]: 0\n",
      "Missing values [Sex]: 0\n",
      "Missing values [Age]: 177\n",
      "Missing values [SibSp]: 0\n",
      "Missing values [Parch]: 0\n",
      "Missing values [Ticket]: 0\n",
      "Missing values [Fare]: 0\n",
      "Missing values [Cabin]: 687\n",
      "Missing values [Embarked]: 2\n",
      "\n",
      "Unique values [PassengerId]: 891\n",
      "Unique values [Survived]: 2\n",
      "Unique values [Pclass]: 3\n",
      "Unique values [Name]: 891\n",
      "Unique values [Sex]: 2\n",
      "Unique values [Age]: 89\n",
      "Unique values [SibSp]: 7\n",
      "Unique values [Parch]: 7\n",
      "Unique values [Ticket]: 681\n",
      "Unique values [Fare]: 248\n",
      "Unique values [Cabin]: 148\n",
      "Unique values [Embarked]: 4\n"
     ]
    }
   ],
   "source": [
    "# Código alternativo para calcular valores nulos y únicos\n",
    "\n",
    "# Valores nulos\n",
    "for c in df.columns:\n",
    "    print(\"Missing values [{0}]:\".format(c), df[c].isna().sum())\n",
    "print()\n",
    "\n",
    "# Valores únicos    \n",
    "for c in df.columns:\n",
    "    print(\"Unique values [{0}]:\".format(c), df[c].unique().size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformar DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       "0           0       3    1  22.0      1      0   7.2500         2\n",
       "1           1       1    0  38.0      1      0  71.2833         0\n",
       "2           1       3    0  26.0      0      0   7.9250         2\n",
       "3           1       1    0  35.0      1      0  53.1000         2\n",
       "4           0       3    1  35.0      0      0   8.0500         2\n",
       "..        ...     ...  ...   ...    ...    ...      ...       ...\n",
       "885         0       3    0  39.0      0      5  29.1250         1\n",
       "886         0       2    1  27.0      0      0  13.0000         2\n",
       "887         1       1    0  19.0      0      0  30.0000         2\n",
       "889         1       1    1  26.0      0      0  30.0000         0\n",
       "890         0       3    1  32.0      0      0   7.7500         1\n",
       "\n",
       "[712 rows x 8 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Carga el fichero \n",
    "df = pd.read_csv(\"titanic.csv\")\n",
    "\n",
    "# Elimina columnas no relevantes y filas con valores algún valor vacío, invocamos al método drop y dropna\n",
    "df = df.drop(columns=['PassengerId', 'Name', 'Ticket','Cabin'])\n",
    "df = df.dropna()\n",
    "# Recordad que con el parámetro thresh se puede indicar el mínimo de valores vacíos. En este caso elimino \n",
    "# todas las filas que tengan valores vacíos.\n",
    "\n",
    "# Queremos transformar las columnas que almacenan cadenas de texto para que representen esa información como números naturales.\n",
    "# Esto funciona de la siguiente forma: \n",
    "# Para calcular los valores numéricos lo primero que hacemos es seleccionar la columna, la reinterpretamos \n",
    "# como una categoría astype('category') y finalmente nos quedamos con la secuencia de su representación numérica (cat.codes).\n",
    "# Al reinterpretar la columna como una categoría, se recorren los valores detectando los valores únicos y dándoles \n",
    "# una representación numérica única.\n",
    "\n",
    "df['Sex'] = df['Sex'].astype('category').cat.codes\n",
    "df['Embarked'] = df['Embarked'].astype('category').cat.codes\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De esta forma la columna Sex toma valores 0 y 1; la columna Embarqued toma valores 0, 1, 2."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Salvar a ficheros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-29-b1fd7f6713e3>:8: FutureWarning: As the xlwt package is no longer maintained, the xlwt engine will be removed in a future version of pandas. This is the only engine in pandas that supports writing in the xls format. Install openpyxl and write to an xlsx file instead. You can set the option io.excel.xls.writer to 'xlwt' to silence this warning. While this option is deprecated and will also raise a warning, it can be globally set and the warning suppressed.\n",
      "  df.to_excel('titanic_ml.xls', index=False)\n"
     ]
    }
   ],
   "source": [
    "# A formato CSV, con index = False indicamos que no incluya una columna inicial con el índice de cada fila.\n",
    "# Una vez realizadas todas las transformaciones, lo que hacemos es salvar a disco para poder reutilizarlo cuando queramos.\n",
    "df.to_csv('titanic_ml.csv', index=False)\n",
    "# Con index = False, no crea una columna inicial por defecto de índices.\n",
    "\n",
    "# A formato Excel (XLS y XLSX)\n",
    "# La hoja se llamará 'Sheet1'\n",
    "df.to_excel('titanic_ml.xls', index=False) \n",
    "df.to_excel('titanic_ml.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insertar varias hojas en un fichero Excel\n",
    "writer = pd.ExcelWriter('titanic_2.xlsx')\n",
    "df.to_excel(writer, sheet_name='Hoja 1', index=False)\n",
    "df.to_excel(writer, sheet_name='Hoja 2', index=False)\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aprendizaje automático con Scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.24.1'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Versión de scikit-learn\n",
    "import sklearn\n",
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El “Machine Learning” o aprendizaje automático es una rama de la informática que utiliza técnicas matemáticas y estadísticas para desarrollar sistemas que aprenden a partir de conjuntos de datos. El aprendizaje consiste en la detección y extracción de patrones que se observan del conjunto de datos objeto de aprendizaje.\n",
    "\n",
    "Ejemplo. Detectar que es altamente probable sobrevivir al hundimiento del Titanic si se viajó en primera clase, descubrir que la mayoría de los clientes que compran leche, compran también galletas en el mismo día,…\n",
    "\n",
    "Los datos por sí solos no nos dicen nada, pero al aprender sobre ellos extraemos conocimiento que nos proporciona un entendimiento más preciso de la realidad y nos permite tomar mejores decisiones.\n",
    "\n",
    "Atributos nominales, los valores no tienen ninguna noción de orden o lejanía entre ellos, p.e. el deporte favorito de una persona.\n",
    "\n",
    "Atributos ordinales, los valores tienen un orden y noción de lejanía, p.e. en el caso del Titanic, el atributo Pclass indica la clase de billete adquirida.\n",
    "\n",
    "Atributos continuos, almacenan valores numéricos arbitrarios en un rango dado, p.e. la edad (Age), el precio del billete (Fare) o el número de hermanos y cónyuges (SibSp).\n",
    "\n",
    "Atributo clase, dentro del conjunto de atributos nos ayuda a catalogar la instancia, determina el tipo de aprendizaje automático que queremos realizar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los tipos de aprendizaje, se clasifican en:\n",
    "\n",
    "A) Aprendizaje supervisado. Se realiza sobre conjuntos de datos que tienen un atributo clase, se persigue predecir la clase en función de los valores del resto de atributos. Dependiendo del tipo que tenga la clase se pueden distinguir dos familias:\n",
    "\n",
    "- Clasificación, cuando la clase es un atributo categórico, queremos clasificar una instancia en una de las categorías diferentes a las que puede optar. Un ejemplo sería predecir si un pasajero del Titanic sobrevive o no dependiendo del valor del resto de atributos, en este caso la clase sería el atributo Survived.\n",
    "\n",
    "- Regresión, cuando la clase es un atributo continuo, queremos predecir un valor continuo a partir del resto de atributos. Un ejemplo sería tratar de predecir el precio del billete pagado por cada pasajero del Titanic, donde la clase sería el atributo Fare. \n",
    "\n",
    "B) Aprendizaje no supervisado. Este tipo de aprendizaje se da cuando no disponemos de ningún atributo clase que guíe nuestro aprendizaje, queremos encontrar patrones que aparezcan en nuestro conjunto de datos, un ejemplo podría ser el análisis de grupos que persigue dividir las instancias en conjuntos de elementos similares. Otro ejemplo es poder asociar eventos que ocurren a la vez, por ejemplo el carrito de la compra (cross sell)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centrándonos en el aprendizaje supervisado, a la hora de aplicar aprendizaje automático para obtener un modelo partimos de un conjunto de datos inicial, lo usual es dividir este conjunto en dos fragmentos separados: el conjunto de entrenamiento y el conjunto de test.\n",
    "\n",
    "El conjunto de entrenamiento nos servirá para entrenar nuestro algoritmo y obtener el modelo, mientras que el conjunto de test nos servirá para medir la calidad predictiva del modelo generado.\n",
    "\n",
    "Es importante que el conjunto de entrenamiento y el de test no compartan instancias, lo que queremos es medir lo bien que el conocimiento obtenido durante el entrenamiento se aplica a instancias nuevas no observadas anteriormente.\n",
    "\n",
    "Se suele realizar un muestreo aleatorio 70-80% de instancias para el entrenamiento y el resto de instancias para la evaluación de la calidad (test)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocesado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En algunas ocasiones no necesitaremos utilizar todas las columnas para realizar el aprendizaje automático, por ello, el primer paso consiste en realizar la selección de los atributos que más nos interese. Por ejemplo, el fichero Titanic contiene 11 atributos más la clase, pero no todos parecen demasiado útiles, el nombre de cada persona podríamos omitirlo, acaso llamarse Eufemio puede aumentar la probabilidad de sobrevivir a un naufragio?\n",
    "\n",
    "En otras ocasiones nos podemos encontrar con atributos que no parecen muy relevantes, pero de los que quizá se pueda extraer información interesante. El camarote donde viajaba un pasajero es una cadena de texto con un identificador alfanumérico, podemos extraer esa información y analizar en la cubierta en que estaba el camarote, distancia hasta el bote de emergencia, personas alojadas en el camarote. \n",
    "\n",
    "Otro paso importante es decidir qué hacer con los valores vacíos, una opción es asignar un valor concreto a estos valores vacíos, usando el valor promedio del atributo, el valor máximo o la moda. Esta transformación se conoce como imputer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para partir un DataFrame en train+test y separar también la columna clase\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Utilizamos el método train_test_split para dividir el conjunto original\n",
    "# Cada uno de estos conjuntos será un Dataframe de pandas.\n",
    "# Luego procedemos a separarlos train_y, test_y serán objetos Series\n",
    "# train_x, text_x serán objetos Dataframe\n",
    "# split_label acepta como parámetros el dataframe, una proporción que formará parte del conjunto test y el nombre de la clase\n",
    "# nos devuelve 4 conjunto de datos.\n",
    "\n",
    "def split_label(df, test_size, label):\n",
    "# Utilizando el método train_test_split, dividimos el conjunto df en train y test, donde test tendrá una proporción test_size\n",
    "# sobre el conjunto de datos original.\n",
    "\n",
    "    train, test = train_test_split(df, test_size=test_size)\n",
    "\n",
    "# Como df.columns nos devuelve un índice de Pandas con todas las columnas, eliminamos la columna label.\n",
    "    features = df.columns.drop(label)\n",
    "\n",
    "# Nos quedamos con train y test, pero a su vez dividmos en X para los atributos e Y para la clase.\n",
    "\n",
    "    train_X = train[features]\n",
    "    train_y = train[label]\n",
    "    test_X = test[features]\n",
    "    test_y = test[label]\n",
    "    \n",
    "    return train_X, train_y, test_X, test_y   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 7)\n",
      "(143, 7)\n",
      "(569,)\n",
      "(143,)\n"
     ]
    }
   ],
   "source": [
    "# División en train (80%) y test (20%) para clasificación, con clase 'Survived'\n",
    "titanic = pd.read_csv('titanic_ml.csv')\n",
    "train_X, train_y, test_X, test_y = split_label(titanic, 0.2, 'Survived')\n",
    "\n",
    "# train_X y test_X son DataFrames\n",
    "# train_y y test_y son Series\n",
    "\n",
    "print(train_X.shape)\n",
    "print(test_X.shape)\n",
    "\n",
    "print(train_y.shape)\n",
    "print(test_y.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Técnica de OneHotEncoding\n",
    "\n",
    "Embarked\tEmbarked_C\tEmbarked_Q\tEmbarked_S\n",
    "    C\t        1\t        0\t       0\n",
    "    Q\t        0\t        1\t       0\n",
    "    S\t        0\t        0\t       1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "<class 'numpy.ndarray'>\n",
      "(569, 9)\n",
      "float64\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "(569, 7)\n"
     ]
    }
   ],
   "source": [
    "# One hot encoding de la columna 'Embarked'\n",
    "# Realizamos dos pasos de preprocesado, one hot encoding\n",
    "# En nuestro caso queremos codificar el atributo Embarked, indicamos el índice de dicho atributo.\n",
    "# Por ejemplo Embarqued = Q, S, C, creamos tres nuevos atributos, de forma que si Embarqued = Q, \n",
    "# Embarqued_Q = 1, Embarqued_S = 0, Embarqued_C = 0.\n",
    "# Con esto conseguimos que no haya diferencias para un algortimo de aprendizaje entre los embarques.\n",
    "# Y utilizar la información de embarque con otros análisis con datos complementarios.\n",
    "\n",
    "# from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# get_loc nos sirve para obtener el índice de la columna Embarked de nuestro DataFrame.\n",
    "\n",
    "index_Embarked = train_X.columns.get_loc('Embarked')\n",
    "print(index_Embarked)\n",
    "\n",
    "# Transformamos train_X con el método fit_transform detectando los distintos valores de la columna\n",
    "# generando el conjunto de datos train_X_1\n",
    "\n",
    "# Con sparse = False indicamos que el objeto de salida sea un ndarray en lugar de matrices.\n",
    "ohe = ColumnTransformer([(\"Embarked\", OneHotEncoder(), [index_Embarked])], sparse_threshold = 0,  remainder = 'passthrough')\n",
    "\n",
    "# ohe = OneHotEncoder(categorical_features=[index_Embarked], sparse=False)\n",
    "\n",
    "train_X_1 = ohe.fit_transform(train_X)\n",
    "\n",
    "# train_X_1 es un objeto ndarray de tamaño (569, 9) y tipo float64\n",
    "print(type(train_X_1))\n",
    "print(train_X_1.shape)\n",
    "print(train_X_1.dtype)\n",
    "\n",
    "\n",
    "print(type(train_X))\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.    0.    1.    1.    1.   45.    0.    0.   26.55]\n",
      "[ 0.    0.    1.    3.    1.   19.    0.    0.    7.65]\n",
      "[ 0.  0.  1.  2.  0. 40.  0.  0. 13.]\n"
     ]
    }
   ],
   "source": [
    "# Muestra las 3 primeras entradas de train_X_1\n",
    "for i in range(3): \n",
    "    print(train_X_1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(569, 9)\n",
      "float64\n",
      "[0.         0.         1.         0.         1.         0.560191\n",
      " 0.         0.         0.05182215]\n",
      "[0.         0.         1.         1.         1.         0.23347575\n",
      " 0.         0.         0.01493181]\n",
      "[0.         0.         1.         0.5        0.         0.49736115\n",
      " 0.         0.         0.02537431]\n"
     ]
    }
   ],
   "source": [
    "# En esta segunda fase de preprocesado, realizamos un escalado al rango [0,1] de todos los atributos\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "train_X_2 = min_max_scaler.fit_transform(train_X_1)\n",
    "\n",
    "print(type(train_X_2))\n",
    "print(train_X_2.shape)\n",
    "print(train_X_2.dtype)\n",
    "\n",
    "# Muestra las 3 primeras entradas de train_X_2\n",
    "for i in range(3): \n",
    "    print(train_X_2[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por ejemplo, para un dataset, podemos analizar el valor mínimo y máximo observable con valores entre 30 y -10. Podemos normalizar cualquier valor, p.e. 18.8 como sigue:\n",
    "\n",
    "- y = (x – min) / (max – min);\n",
    "- y = (18.8 – (-10)) / (30 – (-10));\n",
    "- y = 28.8 / 40;\n",
    "- y = 0.72"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificación"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://es.wikipedia.org/wiki/M%C3%A1quinas_de_vectores_de_soporte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(143, 7)\n",
      "(143, 9)\n",
      "Precisión sobre test: 0.7622377622377622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7622377622377622"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "# Lo primero que vamos a utilizar es crear un objeto clasificador y entrenarlo.\n",
    "# Entrenamiento basado en Support Vector Machines, a partir de la ejecución de clf.fit el objeto clf estará entrenado\n",
    "# y nos servirá para clasificar nuevas instancias; train_y representa la columna Survived, train_X_2 lo hemos normalizado \n",
    "# y aplicamos clf.fit sobre ambos conjuntos, cuántos sobrevivieron dependiendo de los atributos train_X_2??\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(train_X_2, train_y)\n",
    "\n",
    "# Transformación del conjunto de test (one hot encoding y escalado) al número de instancias 9 \n",
    "# El conjunto de instancias test_X es transformado con ohe, y después con min_max_scaler, generando 9 atributos test_X_2\n",
    "print(test_X.shape)\n",
    "test_X_2 = min_max_scaler.transform(ohe.transform(test_X))\n",
    "print(test_X_2.shape)\n",
    "\n",
    "# Evaluación del modelo mediante precisión\n",
    "print(\"Precisión sobre test:\", clf.score(test_X_2, test_y)) \n",
    "\n",
    "# Uso del modelo, clf.predict(test_X_2) nos da las predicciones sobre el modelo, test_y los valores reales (si sobrevivió o no)\n",
    "clf.predict(test_X_2)\n",
    "clf.score(test_X_2, test_y)\n",
    "\n",
    "# Esta función nos dará una tasa de aciertos de casi el 80% (ver resultado) en nuestro conjunto de 143 instancias de test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión sobre test: 0.7482517482517482\n"
     ]
    }
   ],
   "source": [
    "# Clasificación usando kNN, k-vecinos más cercanos.\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(train_X_2, train_y)\n",
    "\n",
    "# Evaluación del modelo mediante precisión\n",
    "print(\"Precisión sobre test:\", clf.score(test_X_2, test_y)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso debemos seleccionar un atributo continuo como clase, podría ser Fare (el importe del billete)... Vamos a tratar de predecir en este caso la tarifa pagada en función del resto de atributos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.5208260328145933\n",
      "MSE: 720.0385750459442\n",
      "MAE: 20.252416083916085\n"
     ]
    }
   ],
   "source": [
    "# Regresión lineal\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "# separación train-test con clase 'Fare'\n",
    "titanic = pd.read_csv('titanic_ml.csv')\n",
    "train_X, train_y, test_X, test_y = split_label(titanic, 0.2, 'Fare')\n",
    "\n",
    "# one hot encoding\n",
    "index_Embarked = train_X.columns.get_loc('Embarked')\n",
    "# Con sparse = False indicamos que el objeto de salida sea un ndarray en lugar de matrices.\n",
    "# ohe = OneHotEncoder(categorical_features=[index_Embarked], sparse=False)\n",
    "ohe = ColumnTransformer([(\"Embarked\", OneHotEncoder(), [index_Embarked])], sparse_threshold = 0, remainder = 'passthrough')\n",
    "\n",
    "train_X_1 = ohe.fit_transform(train_X)\n",
    "\n",
    "# Escalado de atributos al rango [0,1]\n",
    "min_max_scaler = MinMaxScaler()\n",
    "train_X_2 = min_max_scaler.fit_transform(train_X_1)\n",
    "\n",
    "# Entrenamiento\n",
    "# Utilizaremos la regresión lineal sobre el conjunto de datos de entrenamiento.\n",
    "# Y entrenaremos al conjunto de datos con el método fit y así comprobar la calidad del modelo generado.\n",
    "reg = LinearRegression()\n",
    "reg.fit(train_X_2, train_y)\n",
    "\n",
    "# Transformación del conjunto de test (one hot encoding y escalado)\n",
    "test_X_2 = min_max_scaler.transform(ohe.transform(test_X))\n",
    "\n",
    "# Evaluación del modelo mediante métrica R^2 y MSE\n",
    "# Utilizamos el error cuadrático medio o el error absoluto medio.\n",
    "print(\"R^2:\", reg.score(test_X_2, test_y)) \n",
    "\n",
    "# Uso y evaluación del modelo con MSE (error cuadrático medio) y MAE (error absoluto medio), pasamos como parámetros \n",
    "# los valores test_y (reales) y pred (predichos)\n",
    "pred = reg.predict(test_X_2)\n",
    "print(\"MSE:\", mean_squared_error(test_y, pred))\n",
    "print(\"MAE:\", mean_absolute_error(test_y, pred))\n",
    "\n",
    "# Según el error absoluto medio la regresión lineal obtiene resultados que se alejan unas 20 libras del precio real.\n",
    "# Considerando que los precios de los billetes están entre 0 y 513 libras, parece un modelo suficientemente preciso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-42-147818a03940>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-42-147818a03940>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    reg = LinearRegression()\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Regresión usando kNN\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "    reg = LinearRegression()\n",
    "    reg.fit(train_X_2, train_y)\n",
    "\n",
    "# Evaluación del modelo mediante métrica R^2\n",
    "print(\"R^2:\", reg.score(test_X_2, test_y)) \n",
    "\n",
    "# Uso y evaluación del modelo con MSE y MAE\n",
    "pred = reg.predict(test_X_2)\n",
    "print(\"MSE:\", mean_squared_error(test_y, pred))\n",
    "print(\"MAE:\", mean_absolute_error(test_y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering (algoritmo no supervisado)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a dividir el conjunto de datos de los pasajeros del Titanic en conjuntos de pasajeros similares, con ello realizaremos un análisis de grupos. Uno de los algoritmos más utilizados para este tipo de aprendizaje es KMeans.\n",
    "Este es un algoritmo iterativo que particiona las instancias en k grupos disjuntos, el valor de k es fijado por el usuario, de forma que se van refinando iterativamente hasta que los grupos no cambian. En cada iteracción se calcula el centroide del grupo, es decir, la instancia promedio que en cada atributo toma como valor la media aritmética de los valores de dicho atributo en todas las instancias del grupo. Una vez calculados los k-centroides, divide las instancias en los k grupos asignando cada una al centroide más cercano.\n",
    "En el caso de los pasajeros del Titanic, no tenemos un atributo clase que haya que separar, luego aplicar k-means es relativamente sencillo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centros de los clústeres:\n",
      " [[-1.94289029e-16  3.79146919e-02  9.62085308e-01  9.90521327e-01\n",
      "   4.95260664e-01  3.27014218e-01  3.43576883e-01  9.95260664e-02\n",
      "   9.47867299e-02  7.78150129e-02]\n",
      " [-2.49800181e-16  5.39083558e-02  9.46091644e-01  1.05471187e-15\n",
      "   7.77628032e-01  8.49056604e-01  3.75477998e-01  1.11051213e-01\n",
      "   6.01976640e-02  3.85185852e-02]\n",
      " [ 1.00000000e+00  6.93889390e-18  6.66133815e-16  6.07692308e-01\n",
      "   3.73076923e-01  5.30769231e-01  3.81939799e-01  8.46153846e-02\n",
      "   6.92307692e-02  1.33306411e-01]]\n",
      "silhouette_score: 0.40360335882884407\n",
      "calinski_harabasz: 369.21898121397436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.31150832, 0.31789029, 1.73984874],\n",
       "       [1.52274362, 2.0626726 , 0.77530662],\n",
       "       [0.62284202, 1.33998748, 1.69060722],\n",
       "       ...,\n",
       "       [0.62174709, 1.53881024, 1.6169074 ],\n",
       "       [1.62637004, 1.88275404, 0.73107457],\n",
       "       [1.88829988, 1.37090166, 1.73454341]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "# from sklearn.metrics import silhouette_score, calinski_harabaz_score\n",
    "from sklearn.metrics import silhouette_score, calinski_harabasz_score\n",
    "\n",
    "\n",
    "titanic = pd.read_csv('titanic_ml.csv')\n",
    "\n",
    "# one hot encoding\n",
    "index_Embarked = titanic.columns.get_loc('Embarked')\n",
    "# ohe = OneHotEncoder(categorical_features=[index_Embarked], sparse=False)\n",
    "ohe = ColumnTransformer([(\"Embarked\", OneHotEncoder(), [index_Embarked])], sparse_threshold = 0, remainder = 'passthrough')\n",
    "\n",
    "titanic_1 = ohe.fit_transform(titanic)\n",
    "\n",
    "# Escalado de atributos al rango [0,1]\n",
    "min_max_scaler = MinMaxScaler()\n",
    "titanic_2 = min_max_scaler.fit_transform(titanic_1)\n",
    "\n",
    "# Clustering\n",
    "clu = KMeans(n_clusters=3)\n",
    "clu.fit(titanic_2)\n",
    "print(\"Centros de los clústeres:\\n\", clu.cluster_centers_)\n",
    "\n",
    "# Evaluación de los clústeres\n",
    "print('silhouette_score:', silhouette_score(titanic_2, clu.labels_))\n",
    "print('calinski_harabasz:', calinski_harabasz_score(titanic_2, clu.labels_))\n",
    "\n",
    "# Comprobar distancia a cada centroide para las instancias de titanic_2 (podrían ser otro conjunto de datos)\n",
    "clu.transform(titanic_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precisión: 0.7972027972027972\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "## Preprocesado\n",
    "\n",
    "# División en train (80%) y test (20%) para clasificación, con clase 'Survived'\n",
    "titanic = pd.read_csv('titanic_ml.csv')\n",
    "train_X, train_y, test_X, test_y = split_label(titanic, 0.2, 'Survived')\n",
    "\n",
    "# Etapa one hot encoding\n",
    "index_Embarked = train_X.columns.get_loc('Embarked')\n",
    "# ohe = OneHotEncoder(categorical_features=[index_Embarked], sparse=False)\n",
    "ohe = ColumnTransformer([(\"Embarked\", OneHotEncoder(), [index_Embarked])], sparse_threshold = 0, remainder = 'passthrough')\n",
    "\n",
    "\n",
    "# Etapa de escalado de atributos al rango [0,1]\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Etapa de clasificación\n",
    "svm = SVC()\n",
    "\n",
    "# Creación del pipeline\n",
    "pipe = Pipeline([('ohe', ohe), ('sca', min_max_scaler), ('clf', svm)])\n",
    "\n",
    "# Entranamiento del pipeline\n",
    "pipe.fit(train_X, train_y)\n",
    "\n",
    "# Evaluación del pipeline\n",
    "print('precisión:', pipe.score(test_X, test_y))\n",
    "\n",
    "# Uso del modelo\n",
    "pipe.predict(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2: 0.30926073932241327\n",
      "[ 25.515625  13.578125  66.53125   65.640625  74.671875  85.0625\n",
      "  46.390625  73.671875  37.796875  -5.109375  -2.453125  72.21875\n",
      "   4.03125   33.296875  29.328125  82.796875   1.125     40.09375\n",
      "  11.953125  -3.234375  78.234375  84.59375   83.21875   55.609375\n",
      "   1.140625  -8.140625  -2.078125  40.5625    11.015625  58.25\n",
      "  55.984375  12.515625  81.015625  -2.265625  44.328125  72.6875\n",
      "  -6.265625  -2.265625  26.296875  -5.296875  -3.421875  62.046875\n",
      "  -2.265625  22.984375  -2.859375   4.984375  61.71875   46.84375\n",
      "  33.109375  30.140625   9.734375  90.984375  -5.515625  61.84375\n",
      "  32.171875  28.921875  16.75      79.578125  32.46875   -4.734375\n",
      "  -2.453125  33.984375   5.5625    26.484375   4.734375  17.5625\n",
      "  86.1875    80.140625  82.6875    95.234375 -10.234375  24.59375\n",
      "  53.890625  -5.515625  52.328125  -2.453125  12.109375  21.359375\n",
      "  46.625     84.28125   32.921875  87.5625    -7.015625  34.234375\n",
      "  64.703125  -2.859375  -6.640625  27.234375  33.40625   -2.859375\n",
      "  -5.5625    13.203125  -3.609375  -5.9375    -4.734375   5.9375\n",
      "  69.1875    47.34375   58.         4.25      80.265625  81.28125\n",
      "  84.609375  -2.671875  -2.265625  68.296875  63.078125  12.859375\n",
      "  11.78125   -3.609375  79.234375  73.53125   80.515625  -3.796875\n",
      "  -2.671875  46.140625  36.09375   32.078125  30.265625  69.890625\n",
      "  78.109375  -3.328125  29.890625  50.734375  24.421875  15.53125\n",
      "  43.9375    -9.203125  68.296875   2.765625  45.265625  54.328125\n",
      "  81.65625   -2.671875  29.890625  76.296875  40.453125  62.234375\n",
      "  85.640625  -2.859375  -5.125      2.28125   57.9375  ]\n",
      "MSE: 3637.7723189083963\n",
      "MAE: 24.960609615384612\n"
     ]
    }
   ],
   "source": [
    "# Pipeline para regresión\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "## Preprocesado\n",
    "\n",
    "# División en train (80%) y test (20%) para clasificación, con clase 'Fare'\n",
    "titanic = pd.read_csv('titanic_ml.csv')\n",
    "train_X, train_y, test_X, test_y = split_label(titanic, 0.2, 'Fare')\n",
    "\n",
    "# Etapa de one hot encoding\n",
    "index_Embarked = train_X.columns.get_loc('Embarked')\n",
    "# ohe = OneHotEncoder(categorical_features=[index_Embarked], sparse=False)\n",
    "ohe = ColumnTransformer([(\"Embarked\", OneHotEncoder(), [index_Embarked])], sparse_threshold = 0, remainder = 'passthrough')\n",
    "\n",
    "# Etapa de escalado de atributos al rango [0,1]\n",
    "min_max_scaler = MinMaxScaler()\n",
    "\n",
    "# Etapa de regresión\n",
    "lin = LinearRegression()\n",
    "\n",
    "# Creación del pipeline\n",
    "pipe = Pipeline([('ohe', ohe), ('sca', min_max_scaler), ('reg', lin)])\n",
    "\n",
    "# Entranamiento del pipeline\n",
    "pipe.fit(train_X, train_y)\n",
    "\n",
    "# Evaluación R^2 del pipeline\n",
    "print('R^2:', pipe.score(test_X, test_y))\n",
    "\n",
    "# Uso del modelo y evaluación MSE\n",
    "pred = pipe.predict(test_X)\n",
    "print(pred)\n",
    "print('MSE:', mean_squared_error(test_y, pred))\n",
    "print(\"MAE:\", mean_absolute_error(test_y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centros de los clústeres:\n",
      " [[ 1.00000000e+00  6.93889390e-18  6.66133815e-16  6.07692308e-01\n",
      "   3.73076923e-01  5.30769231e-01  3.81939799e-01  8.46153846e-02\n",
      "   6.92307692e-02  1.33306411e-01]\n",
      " [-1.94289029e-16  3.79146919e-02  9.62085308e-01  9.90521327e-01\n",
      "   4.95260664e-01  3.27014218e-01  3.43576883e-01  9.95260664e-02\n",
      "   9.47867299e-02  7.78150129e-02]\n",
      " [-2.49800181e-16  5.39083558e-02  9.46091644e-01  1.05471187e-15\n",
      "   7.77628032e-01  8.49056604e-01  3.75477998e-01  1.11051213e-01\n",
      "   6.01976640e-02  3.85185852e-02]]\n",
      "silhouette_score: 0.40360335882884407\n",
      "calinski_harabaz: 369.21898121397425\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "titanic = pd.read_csv('titanic_ml.csv')\n",
    "\n",
    "# Etapa de one hot encoding\n",
    "index_Embarked = titanic.columns.get_loc('Embarked')\n",
    "# ohe = OneHotEncoder(categories = 'auto', categorical_features=[index_Embarked], sparse=False)\n",
    "ohe = ColumnTransformer([(\"Embarked\", OneHotEncoder(), [index_Embarked])], sparse_threshold = 0, remainder = 'passthrough')\n",
    "\n",
    "# Etapa de escalado en rango [0,1]\n",
    "sca = MinMaxScaler()\n",
    "\n",
    "# Etapa de clustering\n",
    "clu = KMeans(n_clusters=3)\n",
    "\n",
    "# Creación del pipeline\n",
    "pipe = Pipeline([('ohe', ohe), ('sca', sca), ('clu',clu)])\n",
    "\n",
    "# Entrenamiento del pipeline\n",
    "pipe.fit(titanic)\n",
    "print(\"Centros de los clústeres:\\n\", pipe.named_steps['clu'].cluster_centers_)\n",
    "\n",
    "# Evaluación de los clústeres\n",
    "print('silhouette_score:', silhouette_score(titanic_2, pipe.named_steps['clu'].labels_))\n",
    "print('calinski_harabaz:', calinski_harabasz_score(titanic_2, pipe.named_steps['clu'].labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persistencia de modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centros de los clústeres:\n",
      " [[-2.49800181e-16  5.39083558e-02  9.46091644e-01  1.05471187e-15\n",
      "   7.77628032e-01  8.49056604e-01  3.75477998e-01  1.11051213e-01\n",
      "   6.01976640e-02  3.85185852e-02]\n",
      " [-1.94289029e-16  3.79146919e-02  9.62085308e-01  9.90521327e-01\n",
      "   4.95260664e-01  3.27014218e-01  3.43576883e-01  9.95260664e-02\n",
      "   9.47867299e-02  7.78150129e-02]\n",
      " [ 1.00000000e+00  6.93889390e-18  6.66133815e-16  6.07692308e-01\n",
      "   3.73076923e-01  5.30769231e-01  3.81939799e-01  8.46153846e-02\n",
      "   6.92307692e-02  1.33306411e-01]]\n",
      "silhouette_score: 0.40360335882884407\n",
      "calinski_harabasz: 369.21898121397436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['kmeans.pkl']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Salvar un modelo de clustering k-means\n",
    "# from sklearn.externals import joblib\n",
    "\n",
    "#import sklearn.external.joblib as extjoblib\n",
    "import joblib\n",
    "\n",
    "titanic = pd.read_csv('titanic_ml.csv')\n",
    "\n",
    "index_Embarked = titanic.columns.get_loc('Embarked')\n",
    "# ohe = OneHotEncoder(categorical_features=[index_Embarked], sparse=False)\n",
    "ohe = ColumnTransformer([(\"Embarked\", OneHotEncoder(), [index_Embarked])], sparse_threshold = 0, remainder = 'passthrough')\n",
    "\n",
    "titanic_1 = ohe.fit_transform(titanic)\n",
    "min_max_scaler = MinMaxScaler()\n",
    "titanic_2 = min_max_scaler.fit_transform(titanic_1)\n",
    "\n",
    "clu = KMeans(n_clusters=3)\n",
    "clu.fit(titanic_2)\n",
    "\n",
    "print(\"Centros de los clústeres:\\n\", clu.cluster_centers_)\n",
    "print('silhouette_score:', silhouette_score(titanic_2, clu.labels_))\n",
    "print('calinski_harabasz:', calinski_harabasz_score(titanic_2, clu.labels_))\n",
    "\n",
    "joblib.dump(clu, 'kmeans.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centros de los clústeres:\n",
      " [[-2.49800181e-16  5.39083558e-02  9.46091644e-01  1.05471187e-15\n",
      "   7.77628032e-01  8.49056604e-01  3.75477998e-01  1.11051213e-01\n",
      "   6.01976640e-02  3.85185852e-02]\n",
      " [-1.94289029e-16  3.79146919e-02  9.62085308e-01  9.90521327e-01\n",
      "   4.95260664e-01  3.27014218e-01  3.43576883e-01  9.95260664e-02\n",
      "   9.47867299e-02  7.78150129e-02]\n",
      " [ 1.00000000e+00  6.93889390e-18  6.66133815e-16  6.07692308e-01\n",
      "   3.73076923e-01  5.30769231e-01  3.81939799e-01  8.46153846e-02\n",
      "   6.92307692e-02  1.33306411e-01]]\n",
      "silhouette_score: 0.40360335882884407\n",
      "calinski_harabasz: 369.21898121397436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.31789029, 1.31150832, 1.73984874],\n",
       "       [2.0626726 , 1.52274362, 0.77530662],\n",
       "       [1.33998748, 0.62284202, 1.69060722],\n",
       "       ...,\n",
       "       [1.53881024, 0.62174709, 1.6169074 ],\n",
       "       [1.88275404, 1.62637004, 0.73107457],\n",
       "       [1.37090166, 1.88829988, 1.73454341]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cargar y utilizar un modelo de clustering k-means\n",
    "loaded_clu = joblib.load('kmeans.pkl') \n",
    "\n",
    "print(\"Centros de los clústeres:\\n\", clu.cluster_centers_)\n",
    "print('silhouette_score:', silhouette_score(titanic_2, clu.labels_))\n",
    "print('calinski_harabasz:', calinski_harabasz_score(titanic_2, clu.labels_))\n",
    "clu.transform(titanic_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centros de los clústeres:\n",
      " [[-1.94289029e-16  3.79146919e-02  9.62085308e-01  9.90521327e-01\n",
      "   4.95260664e-01  3.27014218e-01  3.43576883e-01  9.95260664e-02\n",
      "   9.47867299e-02  7.78150129e-02]\n",
      " [-2.49800181e-16  5.39083558e-02  9.46091644e-01  1.05471187e-15\n",
      "   7.77628032e-01  8.49056604e-01  3.75477998e-01  1.11051213e-01\n",
      "   6.01976640e-02  3.85185852e-02]\n",
      " [ 1.00000000e+00  6.93889390e-18  6.66133815e-16  6.07692308e-01\n",
      "   3.73076923e-01  5.30769231e-01  3.81939799e-01  8.46153846e-02\n",
      "   6.92307692e-02  1.33306411e-01]]\n",
      "silhouette_score: 0.40360335882884407\n",
      "calinski_harabaz: 369.21898121397436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['kmeans_pipeline.pkl']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Salvar pipeline de clustering k-means\n",
    "titanic = pd.read_csv('titanic_ml.csv')\n",
    "\n",
    "index_Embarked = titanic.columns.get_loc('Embarked')\n",
    "# ohe = OneHotEncoder(categorical_features=[index_Embarked], sparse=False)\n",
    "ohe = ColumnTransformer([(\"Embarked\", OneHotEncoder(), [index_Embarked])], sparse_threshold = 0, remainder = 'passthrough')\n",
    "\n",
    "sca = MinMaxScaler()\n",
    "clu = KMeans(n_clusters=3)\n",
    "\n",
    "pipe = Pipeline([('ohe', ohe), ('sca', sca), ('clu',clu)])\n",
    "pipe.fit(titanic)\n",
    "\n",
    "print(\"Centros de los clústeres:\\n\", pipe.named_steps['clu'].cluster_centers_)\n",
    "print('silhouette_score:', silhouette_score(titanic_2, pipe.named_steps['clu'].labels_))\n",
    "print('calinski_harabaz:', calinski_harabasz_score(titanic_2, pipe.named_steps['clu'].labels_))\n",
    "\n",
    "joblib.dump(pipe, 'kmeans_pipeline.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centros de los clústeres:\n",
      " [[-1.94289029e-16  3.79146919e-02  9.62085308e-01  9.90521327e-01\n",
      "   4.95260664e-01  3.27014218e-01  3.43576883e-01  9.95260664e-02\n",
      "   9.47867299e-02  7.78150129e-02]\n",
      " [-2.49800181e-16  5.39083558e-02  9.46091644e-01  1.05471187e-15\n",
      "   7.77628032e-01  8.49056604e-01  3.75477998e-01  1.11051213e-01\n",
      "   6.01976640e-02  3.85185852e-02]\n",
      " [ 1.00000000e+00  6.93889390e-18  6.66133815e-16  6.07692308e-01\n",
      "   3.73076923e-01  5.30769231e-01  3.81939799e-01  8.46153846e-02\n",
      "   6.92307692e-02  1.33306411e-01]]\n",
      "silhouette_score: 0.40360335882884407\n",
      "calinski_harabaz: 369.21898121397436\n"
     ]
    }
   ],
   "source": [
    "# Cargar y utilizar un pipeline de clustering k-means\n",
    "loaded_pipe = joblib.load('kmeans_pipeline.pkl') \n",
    "\n",
    "print(\"Centros de los clústeres:\\n\", loaded_pipe.named_steps['clu'].cluster_centers_)\n",
    "print('silhouette_score:', silhouette_score(titanic_2, loaded_pipe.named_steps['clu'].labels_))\n",
    "print('calinski_harabaz:', calinski_harabasz_score(titanic_2, loaded_pipe.named_steps['clu'].labels_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimización de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVC(), n_jobs=4,\n",
       "             param_grid={'C': [1, 2], 'kernel': ['linear', 'rbf']})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn import svm\n",
    "import pandas as pd\n",
    "\n",
    "# División en train (80%) y test (20%) para clasificación, con clase 'Survived'\n",
    "titanic = pd.read_csv('titanic_ml.csv')\n",
    "train_X, train_y, test_X, test_y = split_label(titanic, 0.2, 'Survived')\n",
    "\n",
    "index_Embarked = train_X.columns.get_loc('Embarked')\n",
    "# ohe = OneHotEncoder(categorical_features=[index_Embarked], sparse=False)\n",
    "ohe = ColumnTransformer([(\"Embarked\", OneHotEncoder(), [index_Embarked])], sparse_threshold = 0, remainder = 'passthrough')\n",
    "train_X_1 = ohe.fit_transform(train_X)\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "train_X_2 = min_max_scaler.fit_transform(train_X_1)\n",
    "\n",
    "svc = svm.SVC()\n",
    "\n",
    "parameters = {'kernel': ['linear', 'rbf'], 'C':[1,2] }\n",
    "clf = GridSearchCV(svc, parameters, n_jobs=4)\n",
    "clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'kernel': 'linear'}\n",
      "0.783822387827977\n",
      "SVC(C=1, kernel='linear')\n",
      "0.7622377622377622\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1], dtype=int64)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(clf.best_params_)\n",
    "print(clf.best_score_)\n",
    "print(clf.best_estimator_)\n",
    "\n",
    "print(clf.score(test_X, test_y))\n",
    "clf.predict(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
